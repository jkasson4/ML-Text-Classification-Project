{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54232be2-c75d-4af6-88d8-410f6f9b2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, collections\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizing_tokenizer(text):\n",
    "    return [lemmatizer.lemmatize(word) for word in word_tokenize(text)]\n",
    "\n",
    "# Set stop words\n",
    "stops = sum([lemmatizing_tokenizer(word) for word in stopwords.words('english')], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6313c23d-0431-44b8-986e-402502a1fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify location of folder containing datasets\n",
    "datasets_location = r'C:\\datasets'\n",
    "\n",
    "# State file name, message name, and class name for each dataset\n",
    "datasets = [\"IMDB Dataset\", \"Spam_SMS\", \"fake_job_postings\"]\n",
    "data_message = [\"review\", \"Message\", \"description\"]\n",
    "data_class = [\"sentiment\", \"Class\", \"fraudulent\"]\n",
    "positive_class = [\"positive\", \"ham\", \"0\"]\n",
    "negative_class = [\"negative\", \"spam\", \"1\"]\n",
    "\n",
    "# Assign data lists\n",
    "data = [None] * len(datasets)\n",
    "X = [None] * len(datasets)\n",
    "y = [None] * len(datasets)\n",
    "X_train = [None] * len(datasets)\n",
    "X_test = [None] * len(datasets)\n",
    "y_train = [None] * len(datasets)\n",
    "y_test = [None] * len(datasets)\n",
    "\n",
    "# Read in data from datasets and set train/test split\n",
    "for i, file in enumerate(datasets):\n",
    "    data[i] = pd.read_csv(datasets_location + '\\\\' + file + \".csv\", usecols = [data_message[i], data_class[i]])\n",
    "\n",
    "    X[i] = data[i][data_message[i]].values.astype(str)\n",
    "    y[i] = data[i][data_class[i]].values.astype(str)\n",
    "\n",
    "    X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(X[i], y[i], test_size = 0.7, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28390b4-8e3a-4bde-83fb-5fc7fa97e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "# Assign models\n",
    "nb_model = [None] * len(datasets)\n",
    "\n",
    "# Set pipeline for each Naive Bayes Model -- Utilizes word stops and lemmatizer\n",
    "for i, file in enumerate(datasets):\n",
    "    nb_model[i] = make_pipeline(TfidfVectorizer(stop_words=stops, token_pattern = None, tokenizer=lemmatizing_tokenizer), MultinomialNB())\n",
    "    nb_model[i].fit(X_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba68509c-39fe-4c09-b9dd-d3710b414a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Naive Bayes on 'IMDB Dataset.csv' is 0.8545428571428572\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.89      0.86     17468\n",
      "    positive       0.88      0.82      0.85     17532\n",
      "\n",
      "    accuracy                           0.85     35000\n",
      "   macro avg       0.86      0.85      0.85     35000\n",
      "weighted avg       0.86      0.85      0.85     35000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15546  1922]\n",
      " [ 3169 14363]]\n",
      "\n",
      "The accuracy of Naive Bayes on 'Spam_SMS.csv' is 0.9256791389031266\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      1.00      0.96      3380\n",
      "        spam       1.00      0.44      0.62       522\n",
      "\n",
      "    accuracy                           0.93      3902\n",
      "   macro avg       0.96      0.72      0.79      3902\n",
      "weighted avg       0.93      0.93      0.91      3902\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3380    0]\n",
      " [ 290  232]]\n",
      "\n",
      "The accuracy of Naive Bayes on 'fake_job_postings.csv' is 0.9527804410354745\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     11928\n",
      "           1       0.00      0.00      0.00       588\n",
      "\n",
      "    accuracy                           0.95     12516\n",
      "   macro avg       0.48      0.50      0.49     12516\n",
      "weighted avg       0.91      0.95      0.93     12516\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11925     3]\n",
      " [  588     0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign class predictions\n",
    "nb_y_pred = [None] * len(datasets)\n",
    "\n",
    "# Test model on test data and output accuracy, classification report, and confusion matrix\n",
    "for i, file in enumerate(datasets):\n",
    "    nb_y_pred[i] = nb_model[i].predict(X_test[i])\n",
    "    print(\"The accuracy of Naive Bayes on \\'\" + file + \".csv\\' is {}\".format(accuracy_score(y_test[i], nb_y_pred[i])))\n",
    "    print(\"Classification Report:\\n{}\".format(classification_report(y_test[i], nb_y_pred[i])))\n",
    "    print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test[i], nb_y_pred[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7069948c-a876-4102-88ec-6f210eee663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Logistic Regression\n",
    "\n",
    "# Assign models\n",
    "lr_model = [None] * len(datasets)\n",
    "\n",
    "# Set pipeline for each Logistic Regression -- Utilizes word stops and lemmatizer\n",
    "# class_weight = 'balanced' ensures classes are weighted inversly propertional to their frequency (balances imbalanced data w/o data loss)\n",
    "for i, file in enumerate(datasets):\n",
    "    lr_model[i] = make_pipeline(TfidfVectorizer(stop_words=stops, token_pattern = None, tokenizer=lemmatizing_tokenizer), LogisticRegression(class_weight='balanced'))\n",
    "    lr_model[i].fit(X_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bc304b-e0cd-4bcd-afb0-0f6650e912a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression on 'IMDB Dataset.csv' is 0.876\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87     17468\n",
      "    positive       0.86      0.89      0.88     17532\n",
      "\n",
      "    accuracy                           0.88     35000\n",
      "   macro avg       0.88      0.88      0.88     35000\n",
      "weighted avg       0.88      0.88      0.88     35000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14974  2494]\n",
      " [ 1846 15686]]\n",
      "\n",
      "The accuracy of Logistic Regression on 'Spam_SMS.csv' is 0.9702716555612506\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.98      0.98      3380\n",
      "        spam       0.87      0.92      0.89       522\n",
      "\n",
      "    accuracy                           0.97      3902\n",
      "   macro avg       0.93      0.95      0.94      3902\n",
      "weighted avg       0.97      0.97      0.97      3902\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3308   72]\n",
      " [  44  478]]\n",
      "\n",
      "The accuracy of Logistic Regression on 'fake_job_postings.csv' is 0.9515020773410036\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     11928\n",
      "           1       0.49      0.69      0.57       588\n",
      "\n",
      "    accuracy                           0.95     12516\n",
      "   macro avg       0.74      0.83      0.77     12516\n",
      "weighted avg       0.96      0.95      0.96     12516\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11503   425]\n",
      " [  182   406]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign class predictions\n",
    "lr_y_pred = [None] * len(datasets)\n",
    "\n",
    "# Test model on test data and output accuracy, classification report, and confusion matrix\n",
    "for i, file in enumerate(datasets):\n",
    "    lr_y_pred[i] = lr_model[i].predict(X_test[i])\n",
    "    print(\"The accuracy of Logistic Regression on \\'\" + file + \".csv\\' is {}\".format(accuracy_score(y_test[i], lr_y_pred[i])))\n",
    "    print(\"Classification Report:\\n{}\".format(classification_report(y_test[i], lr_y_pred[i])))\n",
    "    print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test[i], lr_y_pred[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87a3fc59-d000-4fa0-ab07-6724f9972f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong Negative Weight Logistic Regression\n",
    "\n",
    "# Assign models\n",
    "lr_model_sn = [None] * len(datasets)\n",
    "\n",
    "positive_weight = 1\n",
    "negative_weight = 2\n",
    "\n",
    "# Set pipeline for each Logistic Regression -- Utilizes word stops and lemmatizer\n",
    "# Custom class weight mimics 'balanced' except negative class is recieves 2x weight, increasing negative classification accuracy\n",
    "for i, file in enumerate(datasets):\n",
    "    counter = collections.Counter(y[i])\n",
    "    lr_model_sn[i] = make_pipeline(TfidfVectorizer(stop_words=stops, token_pattern = None, tokenizer=lemmatizing_tokenizer), LogisticRegression(class_weight={positive_class[i]:(positive_weight * len(data[i]) / (counter[positive_class[i]])), negative_class[i]:(negative_weight * len(data[i]) / (counter[negative_class[i]]))}))\n",
    "    lr_model_sn[i].fit(X_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df1272cf-3fca-4ca2-a7d8-ac1a5248499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression on 'IMDB Dataset.csv' is 0.8753714285714286\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.93      0.88     17468\n",
      "    positive       0.92      0.82      0.87     17532\n",
      "\n",
      "    accuracy                           0.88     35000\n",
      "   macro avg       0.88      0.88      0.88     35000\n",
      "weighted avg       0.88      0.88      0.88     35000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16209  1259]\n",
      " [ 3103 14429]]\n",
      "\n",
      "The accuracy of Logistic Regression on 'Spam_SMS.csv' is 0.9633521271143004\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.97      0.98      3380\n",
      "        spam       0.82      0.93      0.87       522\n",
      "\n",
      "    accuracy                           0.96      3902\n",
      "   macro avg       0.91      0.95      0.92      3902\n",
      "weighted avg       0.97      0.96      0.96      3902\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3276  104]\n",
      " [  39  483]]\n",
      "\n",
      "The accuracy of Logistic Regression on 'fake_job_postings.csv' is 0.9421540428251838\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     11928\n",
      "           1       0.43      0.74      0.54       588\n",
      "\n",
      "    accuracy                           0.94     12516\n",
      "   macro avg       0.71      0.84      0.76     12516\n",
      "weighted avg       0.96      0.94      0.95     12516\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11359   569]\n",
      " [  155   433]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign class predictions\n",
    "lr_y_pred_sn = [None] * len(datasets)\n",
    "\n",
    "# Test model on test data and output accuracy, classification report, and confusion matrix\n",
    "for i, file in enumerate(datasets):\n",
    "    lr_y_pred_sn[i] = lr_model_sn[i].predict(X_test[i])\n",
    "    print(\"The accuracy of Logistic Regression on \\'\" + file + \".csv\\' is {}\".format(accuracy_score(y_test[i], lr_y_pred_sn[i])))\n",
    "    print(\"Classification Report:\\n{}\".format(classification_report(y_test[i], lr_y_pred_sn[i])))\n",
    "    print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test[i], lr_y_pred_sn[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb14d9-f3d7-4b85-ab33-bc260d3f7700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
