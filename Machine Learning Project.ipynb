{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54232be2-c75d-4af6-88d8-410f6f9b2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizing_tokenizer(text):\n",
    "    return [lemmatizer.lemmatize(word) for word in word_tokenize(text)]\n",
    "\n",
    "# Set stop words\n",
    "stops = sum([lemmatizing_tokenizer(word) for word in stopwords.words('english')], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6313c23d-0431-44b8-986e-402502a1fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify location of folder containing datasets\n",
    "datasets_location = r'C:\\datasets'\n",
    "\n",
    "# State file name, message name, and class name for each dataset\n",
    "datasets = [\"IMDB Dataset\", \"Spam_SMS\", \"fake_job_postings\"]\n",
    "data_message = [\"review\", \"Message\", \"description\"]\n",
    "data_class = [\"sentiment\", \"Class\", \"fraudulent\"]\n",
    "\n",
    "# Assign data lists\n",
    "data = []\n",
    "X = []\n",
    "y = []\n",
    "X_train = [None] * len(datasets)\n",
    "X_test = [None] * len(datasets)\n",
    "y_train = [None] * len(datasets)\n",
    "y_test = [None] * len(datasets)\n",
    "\n",
    "# Read in data from datasets and set train/test split\n",
    "for i, file in enumerate(datasets):\n",
    "    data.append(pd.read_csv(datasets_location + '\\\\' + file + \".csv\", usecols = [data_message[i], data_class[i]]))\n",
    "\n",
    "    temp_X = data[i][data_message[i]].values.astype(str)\n",
    "    X.append(temp_X)\n",
    "    y.append(data[i][data_class[i]].values.astype(str))\n",
    "\n",
    "    X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(X[i], y[i], test_size = 0.7, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28390b4-8e3a-4bde-83fb-5fc7fa97e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign models\n",
    "nb_model = [None] * len(datasets)\n",
    "\n",
    "# Set pipeline for each Naive Bayes Model -- Utilizes word stops and lemmatizer\n",
    "for i, file in enumerate(datasets):\n",
    "    nb_model[i] = make_pipeline(TfidfVectorizer(stop_words=stops, token_pattern = None, tokenizer=lemmatizing_tokenizer), MultinomialNB())\n",
    "    nb_model[i].fit(X_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba68509c-39fe-4c09-b9dd-d3710b414a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Naive Bayes on 'IMDB Dataset.csv' is 0.8545428571428572\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.89      0.86     17468\n",
      "    positive       0.88      0.82      0.85     17532\n",
      "\n",
      "    accuracy                           0.85     35000\n",
      "   macro avg       0.86      0.85      0.85     35000\n",
      "weighted avg       0.86      0.85      0.85     35000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15546  1922]\n",
      " [ 3169 14363]]\n",
      "\n",
      "The accuracy of Naive Bayes on 'Spam_SMS.csv' is 0.9256791389031266\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      1.00      0.96      3380\n",
      "        spam       1.00      0.44      0.62       522\n",
      "\n",
      "    accuracy                           0.93      3902\n",
      "   macro avg       0.96      0.72      0.79      3902\n",
      "weighted avg       0.93      0.93      0.91      3902\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3380    0]\n",
      " [ 290  232]]\n",
      "\n",
      "The accuracy of Naive Bayes on 'fake_job_postings.csv' is 0.9527804410354745\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     11928\n",
      "           1       0.00      0.00      0.00       588\n",
      "\n",
      "    accuracy                           0.95     12516\n",
      "   macro avg       0.48      0.50      0.49     12516\n",
      "weighted avg       0.91      0.95      0.93     12516\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11925     3]\n",
      " [  588     0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign class predictions\n",
    "nb_y_pred = [None] * len(datasets)\n",
    "\n",
    "# Test model on test data and output accuracy, classification report, and confusion matrix\n",
    "for i, file in enumerate(datasets):\n",
    "    nb_y_pred[i] = nb_model[i].predict(X_test[i])\n",
    "    print(\"The accuracy of Naive Bayes on \\'\" + file + \".csv\\' is {}\".format(accuracy_score(y_test[i], nb_y_pred[i])))\n",
    "    print(\"Classification Report:\\n{}\".format(classification_report(y_test[i], nb_y_pred[i])))\n",
    "    print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test[i], nb_y_pred[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069948c-a876-4102-88ec-6f210eee663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign models\n",
    "lr_model = [None] * len(datasets)\n",
    "\n",
    "# Set pipeline for each Logistic Regression -- Utilizes word stops and lemmatizer\n",
    "for i, file in enumerate(datasets):\n",
    "    lr_model[i] = make_pipeline(TfidfVectorizer(stop_words=stops, token_pattern = None, tokenizer=lemmatizing_tokenizer), LogisticRegression())\n",
    "    lr_model[i].fit(X_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "85bc304b-e0cd-4bcd-afb0-0f6650e912a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression on 'IMDB Dataset.csv' is 0.8762\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87     17468\n",
      "    positive       0.86      0.89      0.88     17532\n",
      "\n",
      "    accuracy                           0.88     35000\n",
      "   macro avg       0.88      0.88      0.88     35000\n",
      "weighted avg       0.88      0.88      0.88     35000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15004  2464]\n",
      " [ 1869 15663]]\n",
      "\n",
      "The accuracy of Logistic Regression on 'Spam_SMS.csv' is 0.9359302921578677\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      1.00      0.96      3380\n",
      "        spam       0.98      0.53      0.69       522\n",
      "\n",
      "    accuracy                           0.94      3902\n",
      "   macro avg       0.96      0.77      0.83      3902\n",
      "weighted avg       0.94      0.94      0.93      3902\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3374    6]\n",
      " [ 244  278]]\n",
      "\n",
      "The accuracy of Logistic Regression on 'fake_job_postings.csv' is 0.9608501118568232\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     11928\n",
      "           1       1.00      0.17      0.29       588\n",
      "\n",
      "    accuracy                           0.96     12516\n",
      "   macro avg       0.98      0.58      0.63     12516\n",
      "weighted avg       0.96      0.96      0.95     12516\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11928     0]\n",
      " [  490    98]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign class predictions\n",
    "lr_y_pred = [None] * len(datasets)\n",
    "\n",
    "# Test model on test data and output accuracy, classification report, and confusion matrix\n",
    "for i, file in enumerate(datasets):\n",
    "    lr_y_pred[i] = lr_model[i].predict(X_test[i])\n",
    "    print(\"The accuracy of Logistic Regression on \\'\" + file + \".csv\\' is {}\".format(accuracy_score(y_test[i], lr_y_pred[i])))\n",
    "    print(\"Classification Report:\\n{}\".format(classification_report(y_test[i], lr_y_pred[i])))\n",
    "    print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test[i], lr_y_pred[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
